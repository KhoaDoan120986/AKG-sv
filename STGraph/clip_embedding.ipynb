{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pathlib\n",
    "import h5py\n",
    "import numpy as np\n",
    "from modules.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from modules.modeling import CLIP4Clip\n",
    "from modules.tokenization_clip import SimpleTokenizer as ClipTokenizer\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import json\n",
    "from open_clip import get_tokenizer\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    msvd = False # or msvd = False for MSR-VTT\n",
    "    slice_framepos = 2\n",
    "    dset = \"../\"\n",
    "    max_frames = 20\n",
    "    eval_frame_order = 0\n",
    "    output_dir = 'pretrained'\n",
    "    cache_dir = ''\n",
    "    features_path = '..'\n",
    "    msrvtt_csv = 'msrvtt.csv'\n",
    "    max_words =32\n",
    "    feature_framerate = 1\n",
    "    cross_model = \"cross-base\"\n",
    "    local_rank = 0\n",
    "    pretrained_clip_name = \"ViT-B/16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.4\"\n",
    "model_state_dict = torch.load(model_file, map_location='cpu')\n",
    "cache_dir = args.cache_dir if args.cache_dir else os.path.join(str(PYTORCH_PRETRAINED_BERT_CACHE), 'distributed')\n",
    "model = CLIP4Clip.from_pretrained(args.cross_model, cache_dir=cache_dir, state_dict=model_state_dict, task_config=args)\n",
    "tokenizer = get_tokenizer('ViT-B-32')\n",
    "clip = model.clip.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {} \n",
    "# res[video_id] = {'entities': [], 'relations': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"clip_embeddings.hdf5\", \"w\") as fs:\n",
    "    for key in tqdm(res.keys()):\n",
    "        ent_tokens = tokenizer(res[key]['entities'])\n",
    "        ent_embedding = clip.encode_text(ent_tokens.cuda())\n",
    "\n",
    "        rel_tokens = tokenizer(res[key]['relations'])\n",
    "        rel_embedding = clip.encode_text(rel_tokens.cuda())\n",
    "        embeddings= torch.cat([ent_embedding, rel_embedding]).cpu().detach().numpy()\n",
    "        fs.create_dataset(key, data=embeddings)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
